{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1b681",
   "metadata": {},
   "source": [
    "## Assignments Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197536dc",
   "metadata": {},
   "source": [
    "__Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values. ?__\n",
    "\n",
    "__Ans)__ Missing values refer to the absence of a particular value in a variable for an observation in a dataset. In other words, missing values are represented by NaN (Not a Number) or NA (Not Available) in the dataset. Missing values can occur for various reasons such as human error, data corruption, or incomplete data collection.\n",
    "\n",
    "Handling missing values is crucial because they can affect the accuracy of data analysis and modeling. If missing values are not handled correctly, it can lead to biased results, incorrect predictions, and can affect the performance of machine learning algorithms.\n",
    "\n",
    "__Some algorithms that are not affected by missing values are decision trees, random forests, and K-nearest neighbors (KNN). These algorithms can handle missing values by ignoring observations with missing values or by imputing missing values based on the values of other variables in the dataset. However, it is important to note that the performance of these algorithms can be improved by handling missing values appropriately.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e768e4",
   "metadata": {},
   "source": [
    "__Q2: List down techniques used to handle missing data. Give an example of each with python code.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcd2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  5.0  9.0\n"
     ]
    }
   ],
   "source": [
    "##Deleting rows or columns with missing values:\n",
    "##This method involves removing any observation or variable that contains missing values. It can be used when the percentage of missing values is very low, and it is not significant to the analysis. However, it can result in a loss of valuable data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# creating a sample dataframe with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4],\n",
    "                   'B': [5, np.nan, 7, 8],\n",
    "                   'C': [9, 10, 11, np.nan]})\n",
    "\n",
    "# deleting rows with missing values\n",
    "df.dropna(axis=0, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd8a691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  5.0  9.0\n"
     ]
    }
   ],
   "source": [
    "##Imputing missing values:\n",
    "##This method involves filling missing values with a substitute value based on the available data. The imputation technique used depends on the type of data and the nature of the missing values.\n",
    "# imputing missing values with mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66080de",
   "metadata": {},
   "source": [
    "__Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?__\n",
    "    \n",
    "__Ans)__ Imbalanced data refers to a situation where the distribution of the target variable in a dataset is heavily skewed towards one class. If not handled properly, it can lead to several issues in machine learning modeling and evaluation, including bias towards the majority class, poor model generalization, overfitting, and incorrect evaluation metrics. To address imbalanced data, techniques such as up-sampling, down-sampling, and SMOTE can be used to balance the class distribution and improve the performance and generalization of the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a6388",
   "metadata": {},
   "source": [
    "__Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required.__\n",
    "\n",
    "__Ans)__ Up-sampling and down-sampling are techniques used in machine learning to balance the class distribution in a dataset by either increasing or decreasing the number of samples in a particular class.\n",
    "\n",
    "Up-sampling is a technique used to increase the number of samples in the minority class by randomly duplicating existing samples. This technique is typically used when the number of samples in the minority class is significantly lower than the number of samples in the majority class. The objective of up-sampling is to balance the class distribution and avoid the model from being biased towards the majority class.\n",
    "\n",
    "Down-sampling is a technique used to decrease the number of samples in the majority class by randomly removing samples. This technique is typically used when the number of samples in the majority class is significantly higher than the number of samples in the minority class. The objective of down-sampling is to balance the class distribution and avoid over-representation of the majority class.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose we have a dataset of customer churn, where the target variable is binary, and there are 1000 samples in the dataset. Out of these 1000 samples, 900 samples are from customers who did not churn (majority class), and 100 samples are from customers who churned (minority class). In this scenario, the class distribution is highly imbalanced, and the model can be biased towards the majority class.\n",
    "\n",
    "If we use this imbalanced dataset to train our machine learning model, the model may perform well for the majority class but may perform poorly for the minority class. To balance the class distribution, we can either use up-sampling or down-sampling.\n",
    "\n",
    "If we use up-sampling, we can randomly duplicate the 100 samples of the minority class to have the same number of samples as the majority class. This would increase the size of the dataset to 1800 samples (900 from each class). The up-sampled dataset can then be used to train the machine learning model.\n",
    "\n",
    "If we use down-sampling, we can randomly remove 800 samples from the majority class to have the same number of samples as the minority class. This would decrease the size of the dataset to 200 samples (100 from each class). The down-sampled dataset can then be used to train the machine learning model.\n",
    "\n",
    "__In summary, up-sampling and down-sampling are techniques used to balance the class distribution in a dataset by increasing or decreasing the number of samples in a particular class. These techniques are used when the class distribution is highly imbalanced, and the model can be biased towards the majority class.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c14451",
   "metadata": {},
   "source": [
    "__Q5: What is data Augmentation? Explain SMOTE.__\n",
    "\n",
    "__Ans)__ Data augmentation is a technique used in machine learning to increase the size of a dataset by creating new synthetic samples from the existing ones. The objective of data augmentation is to improve the generalization and robustness of machine learning models by exposing them to a wider range of data variations.\n",
    "\n",
    "One popular data augmentation technique is Synthetic Minority Over-sampling Technique (SMOTE). SMOTE is a technique used to balance the class distribution in a dataset by creating synthetic samples of the minority class. The SMOTE algorithm creates synthetic samples by selecting two or more similar samples from the minority class and then randomly interpolating between them. The new synthetic sample is then added to the dataset, increasing the number of samples in the minority class.\n",
    "\n",
    "The SMOTE algorithm works as follows:\n",
    "\n",
    "* Identify the minority class samples that need to be augmented.\n",
    "* For each minority class sample, identify its k nearest neighbors.\n",
    "* Select one of the k nearest neighbors randomly and compute the difference between the feature values of the minority sample and the selected neighbor.\n",
    "* Multiply the difference by a random number between 0 and 1 and add it to the feature values of the minority sample to create a new synthetic sample.\n",
    "* Repeat steps 3 and 4 until the desired number of synthetic samples has been created.\n",
    "\n",
    "The SMOTE algorithm creates synthetic samples that are similar to the minority class samples, but with small variations. This helps to reduce overfitting and improve the generalization of the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefdbced",
   "metadata": {},
   "source": [
    "__Q6: What are outliers in a dataset? Why is it essential to handle outliers?__\n",
    "    \n",
    "__Ans)__ Outliers are data points that deviate significantly from the other observations in a dataset. They can be caused by measurement errors, data corruption, or natural variations in the data. Outliers can have a significant impact on the statistical analysis and modeling of the data.\n",
    "\n",
    "It is essential to handle outliers because they can significantly affect the results of the data analysis and modeling. Outliers can lead to incorrect statistical estimates, biased models, and incorrect predictions. Outliers can also result in the overfitting of models, where the model is too closely fit to the training data and performs poorly on new data.\n",
    "\n",
    "Handling outliers can improve the accuracy and robustness of the data analysis and modeling. There are several methods for handling outliers, including:\n",
    "\n",
    "* Removing outliers:\n",
    "This method involves removing the outlier data points from the dataset. This can be done manually by visual inspection or using statistical methods such as the z-score, interquartile range (IQR), or boxplot.\n",
    "\n",
    "* Transforming the data:\n",
    "This method involves transforming the data to reduce the effect of outliers. One way to do this is by using a logarithmic or power transformation to reduce the skewness of the data.\n",
    "\n",
    "* Winsorization:\n",
    "This method involves replacing the outlier values with the nearest non-outlier values. This can be done by setting the outlier values to a specific percentile of the data, such as the 1st or 99th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90282593",
   "metadata": {},
   "source": [
    "__Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?__\n",
    "\n",
    "__Ans)__ The list of techniques for handling missing data in a dataset, sorted in alphabetical order:\n",
    "\n",
    "* Deleting missing data.\n",
    "* Imputing missing data.\n",
    "* Multiple imputation.\n",
    "* Using algorithms that can handle missing values.\n",
    "\n",
    "__It is important to carefully consider the advantages and disadvantages of each technique before selecting the appropriate method, depending on the nature and extent of the missing data and the objectives of the analysis.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29478099",
   "metadata": {},
   "source": [
    "__Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?__\n",
    "\n",
    "__Ans)__ To determine if the missing data is missing at random or if there is a pattern to the missing data, the following strategies can be used:\n",
    "\n",
    "* Visual inspection: Visualizing the distribution of the missing values can provide insights into whether the missing data is random or not. This can be done using heatmaps or plots that show the missing values in the dataset.\n",
    "\n",
    "* Statistical tests: Statistical tests can be used to determine if there is a pattern to the missing data. For example, a chi-squared test can be used to test if the missing data is related to another variable in the dataset.\n",
    "\n",
    "* Imputation experiments: Imputation experiments can be used to determine if the missing data is missing at random or if there is a pattern. Multiple imputed datasets can be generated using different imputation methods, and the results can be compared to determine if there are any differences based on the pattern of the missing data.\n",
    "\n",
    "* Domain knowledge: Domain knowledge can be used to determine if there is a pattern to the missing data. For example, if the missing data is related to a specific time period or location, this may suggest a pattern in the missing data.\n",
    "\n",
    "* Machine learning models: Machine learning models can be trained to predict missing values based on other variables in the dataset. The performance of the model can provide insights into whether the missing data is missing at random or if there is a pattern.\n",
    "\n",
    "__In summary, strategies such as visual inspection, statistical tests, imputation experiments, domain knowledge, and machine learning models can be used to determine if the missing data is missing at random or if there is a pattern to the missing data. Understanding the pattern of missing data can help in selecting appropriate techniques for handling missing data and improve the accuracy and robustness of the data analysis and modeling.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7948a6",
   "metadata": {},
   "source": [
    "__Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?__\n",
    "\n",
    "__Ans)__ Some strategies to evaluate the performance of a machine learning model on an imbalanced medical diagnosis dataset are:\n",
    "\n",
    "* Use evaluation metrics that are suitable for imbalanced datasets: Metrics such as precision, recall, F1-score, and area under the Receiver Operating Characteristic (ROC) curve are better suited to imbalanced datasets compared to accuracy.\n",
    "\n",
    "* Use resampling techniques: Techniques such as up-sampling, down-sampling, and Synthetic Minority Over-sampling Technique (SMOTE) can be used to balance the class distribution in the dataset and improve the performance of the machine learning model.\n",
    "\n",
    "* Use appropriate algorithms: Algorithms that can handle imbalanced datasets, such as decision trees, random forests, and gradient boosting, can be used to improve the performance of the machine learning model.\n",
    "\n",
    "* Use cross-validation: Cross-validation can be used to evaluate the performance of the machine learning model on multiple folds of the data, ensuring that the evaluation is robust and unbiased.\n",
    "\n",
    "* Adjust the classification threshold: The classification threshold can be adjusted to balance the trade-off between precision and recall, depending on the specific requirements of the medical diagnosis problem.\n",
    "\n",
    "__In summary, using appropriate evaluation metrics, resampling techniques, algorithms, cross-validation, and adjusting the classification threshold can help improve the performance of machine learning models on imbalanced medical diagnosis datasets.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2919a",
   "metadata": {},
   "source": [
    "__Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?__\n",
    "\n",
    "__Ans)__ To balance an unbalanced dataset with a majority class in customer satisfaction estimation project, we can use the following methods to down-sample the majority class:\n",
    "\n",
    "* Random under-sampling: This method involves randomly selecting a subset of the majority class observations to match the size of the minority class. This can be done using techniques such as the NearMiss algorithm.\n",
    "\n",
    "* Cluster-based under-sampling: This method involves clustering the majority class observations and randomly selecting a subset of the clusters to match the size of the minority class.\n",
    "\n",
    "* Tomek links: This method involves identifying the Tomek links, which are pairs of observations that are the closest to each other, but belong to different classes. Removing the majority class observations from the Tomek links can down-sample the majority class.\n",
    "\n",
    "* Edited nearest neighbors: This method involves removing the majority class observations that are misclassified by their nearest neighbors.\n",
    "\n",
    "* Synthetic Minority Over-sampling Technique (SMOTE): SMOTE involves creating synthetic observations for the minority class by interpolating between the existing minority class observations. This can increase the size of the minority class and balance the dataset.\n",
    "\n",
    "__In summary, we can employ techniques such as random under-sampling, cluster-based under-sampling, Tomek links, edited nearest neighbors, or SMOTE to balance an unbalanced dataset with a majority class in customer satisfaction estimation project. It is important to select the appropriate method based on the nature of the dataset and the objectives of the analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ba451",
   "metadata": {},
   "source": [
    "__Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?__\n",
    "\n",
    "__Ans)__ To balance an unbalanced dataset with a low percentage of occurrences in a project that requires estimating the occurrence of a rare event, we can use the following methods to up-sample the minority class:\n",
    "\n",
    "* Random over-sampling: This method involves randomly duplicating the minority class observations to match the size of the majority class.\n",
    "\n",
    "* Synthetic Minority Over-sampling Technique (SMOTE): SMOTE involves creating synthetic observations for the minority class by interpolating between the existing minority class observations.\n",
    "\n",
    "* Adaptive Synthetic Sampling (ADASYN): ADASYN is an extension of SMOTE that creates synthetic observations with a higher density in regions with fewer minority class observations.\n",
    "\n",
    "* Synthetic Minority Over-sampling Technique using Fuzzy Logic (SMOTE-FL): SMOTE-FL is an extension of SMOTE that considers the degree of uncertainty between the minority and majority class observations to create synthetic observations.\n",
    "\n",
    "* Random minority over-sampling with replacement (ROS): ROS involves randomly sampling with replacement the minority class observations to match the size of the majority class.\n",
    "\n",
    "__In summary, we can employ techniques such as random over-sampling, SMOTE, ADASYN, SMOTE-FL, or ROS to balance an unbalanced dataset with a low percentage of occurrences in a project that requires estimating the occurrence of a rare event. It is important to select the appropriate method based on the nature of the dataset and the objectives of the analysis.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47722a",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------- __End__----------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
